{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT, N = 0, 0\n",
    "chat_history = []\n",
    "chain = ''\n",
    "enable_box = gr.Textbox.update(value=None, \n",
    "                          placeholder='Upload your OpenAI API key', interactive=True)\n",
    "disable_box = gr.Textbox.update(value='OpenAI API key is Set', interactive=False)\n",
    "def database():\n",
    "    with open('database.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the content of the file\n",
    "        document = file.read()\n",
    "    def split_text_into_batches(text, batch_size):\n",
    "\n",
    "        batches = []\n",
    "        for i in range(0, len(text), batch_size):\n",
    "            batch = text[i:i + batch_size]\n",
    "            batches.append(batch)\n",
    "        return batches\n",
    "    documents=split_text_into_batches(str(document),400)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
    "    db = FAISS.from_texts(documents, embeddings)\n",
    "    \n",
    "    return db\n",
    "# Function to set the OpenAI API key\n",
    "def set_apikey(api_key):\n",
    "    os.environ[\"HUGGINFACEHUB_API_TOKEN\"] = api_key\n",
    "    return disable_box\n",
    "def enable_api_box():\n",
    "    return enable_box\n",
    "def add_text(history, text):\n",
    "    if not text:\n",
    "        raise gr.Error('Enter text')\n",
    "    history = history + [(text, '')]\n",
    "    return history\n",
    "def generate_response(history, query):\n",
    "    global COUNT, N, chat_history, chain\n",
    "    db=database()\n",
    "    llm=HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", model_kwargs={\"temperature\":1, \"max_length\":60},huggingfacehub_api_token=\"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\")\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    doc = (db.similarity_search_with_score(query))\n",
    "    score=doc[0][-1]\n",
    "    doc = doc[0][:-1]\n",
    "    threshold = 2\n",
    "    if score > threshold:\n",
    "        # No relevant information found or information is below the specified threshold\n",
    "        result=\"Sorry, but we can't answer that at the moment.\"\n",
    "        print(\"Sorry, but we can't answer that at the moment.\")\n",
    "    else:\n",
    "        # Relevant information found, proceed with the chain\n",
    "        result=chain.run(input_documents=doc, question=query)\n",
    "        print(chain.run(input_documents=doc, question=query))\n",
    "    \n",
    "    chat_history += [(query, result)]\n",
    "\n",
    "    for char in result:\n",
    "        history[-1][-1] += char\n",
    "        yield history, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! How can I help you today?\n",
      " The name Vikash is not mentioned in the provided context.\n",
      " The brother of Bharat is Shatrughna.\n",
      " The brothers of Bharat are Ram and Laxman. However, since you are looking for the brothers of Bharat among Ravana's siblings, there are no such brothers.\n",
      " Janaka\n",
      "\n",
      "\n",
      "It seems like you're discussing a story, possibly from Hindu mythology, about King Dasharatha and his son Rama. Based on the excerpt you've provided, it seems like Dasharatha is lamenting the loss of Rama and is reflecting on his life. He mentions significant events in Rama's life, such as his birth, childhood, and marriage to Sita. Dasharatha then recalls\n",
      " Hanuman's father is Vayu, the god of the wind.\n",
      " Hanuman's mother is Anjana.\n",
      " The text does not provide information about the age of Ravan.\n",
      " If you are rejected, it means that someone has refused or dismissed you or something you have offered. In this context, Sita is rejecting Ravana's advances and refusing to listen to him or look at him. She is also lamenting about how she wishes she had listened to Lakshmana's advice, implying that she feels rejected by her husband Rama as well.\n",
      " This chatbot is created by Anish De and Vikky Kumar.\n",
      " Anish De and Vikky Kumar created this chatbot.\n",
      " Bali is not mentioned in the context.\n",
      " The king of apes is Hanuman.\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    # Create a Gradio block\n",
    "\n",
    "    with gr.Column():\n",
    "        \n",
    "\n",
    "        with gr.Row():\n",
    "            chatbot = gr.Chatbot(value=[], elem_id='chatbot').style(height=570)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=0.80):\n",
    "            txt = gr.Textbox(\n",
    "                show_label=False,\n",
    "                placeholder=\"Enter text and press enter\"\n",
    "            ).style(container=False)\n",
    "\n",
    "        with gr.Column(scale=0.2):\n",
    "            submit_btn = gr.Button('Submit')\n",
    "\n",
    "        \n",
    "\n",
    "    # Set up event handlers\n",
    "\n",
    "    # Event handler for submitting the OpenAI API key\n",
    "\n",
    "    \n",
    "\n",
    "    # Event handler for submitting text and generating response\n",
    "    submit_btn.click(\n",
    "        fn=add_text,\n",
    "        inputs=[chatbot, txt],\n",
    "        outputs=[chatbot],\n",
    "        queue=False\n",
    "    ).success(\n",
    "        fn=generate_response,\n",
    "        inputs=[chatbot, txt],\n",
    "        outputs=[chatbot, txt]\n",
    "    )\n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
